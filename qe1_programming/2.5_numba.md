---
jupyter:
  jupytext:
    formats: ipynb,md
    text_representation:
      extension: .md
      format_name: markdown
      format_version: '1.2'
      jupytext_version: 1.4.1
  kernelspec:
    display_name: Python 3
    language: python
    name: python3
---

# 2.5 numba

```python
!pip install --upgrade quantecon
import numpy as np
import quantecon as qe
import matplotlib.pyplot as plt

%matplotlib inline
```

# 1 overview

1. In the lecture 2.1(**PI:,**) we learned about vectorization.
   - One method to improve speed and efficiency in numerical work.
   - Vectorization involves sending array processing operations in batch to efficient low-level code.
2. However, as we discussed in lecture 2.1, vectorization has several weaknesses.
   - One is that it is highly memory-intensive when working with large amounts of data.
   - Another is that the set of algorithms that can be entirely vectorized is not universal.
     - In fact, for some algorithms, vectorization is ineffective.
3. A new Python library called Numba solves many of these problems.
   - It does so through something called **just-in-time (JIT)** compilation.
     - The **key idea** is to compile functions to native machine code instructions on the fly.
     - When it succeeds, the compiled code is extremely fast.
   - Numba is specifically designed for numerical work and can also do other tricks such as multithreading.
   - Numba will be a key part of our lectures.
     - Especially those lectures involving dynamic programming.
     - This lecture introduces the main ideas.


# 2 compiling functions

1. As stated above, Numba's **primary use** is compiling functions to fast native machine code during runtime.

# 2.1 An example

1. Let's consider a problem that is difficult to vectorize.
   - Problem: generating the trajectory of a difference equation, given an initial condition.
     - We will take the difference equation to the quadratic map, see Program 1:
     $$
     x_{t+1} = \alpha x_t (1 - x_t)
     $$
     - We set `α = 4.0`, see Program 2.
     - See Program 3, the plot of a typical trajectory, starting from $x_0 = 0.1$, with $t$ on the $x$-axis.
   - To speed the function `qm` up using Numba, our first step is to jit it, see Program 4.
     - The function `qm_numba` (**PI1: add ' '**) is a version of `qm` that is "targeted" for JIT-compilation.
       - We will explain it in 2.2.
     - Let's time and compare identical function calls acrss these two versions, starting with the original function `qm`, see Program 5-6.
       - In fact, the 2nd time and all subsequent times it runs even faster as the function has been compiled and is in memory, see Program 7-8 (**PI2: "time2" in Program 7 might be changed to "time3" for clarification**).
         - This kind of speed gain is huge relative to how simple and clear the implementation is.

```python
# Program 1

def qm(x0, n):
    x = np.empty(n+1)
    x[0] = x0
    for t in range(n):
        x[t+1] = α * x[t] * (1 - x[t])
    return x
```

```python
# Program 2
α = 4.0
```

```python
# Program 3

x = qm(0.1, 250)
fig, ax = plt.subplots()
ax.plot(x, 'b-', lw=2, alpha=0.8)
ax.set_xlabel('time', fontsize=16)
plt.show()
```

```python
# Program 4

from numba import jit

qm_numba = jit(qm)
```

```python
# Program 5: non-jit version

n = 10_000_000

qe.tic() # PI3: what's this? a possible link? vs %timeit
qm(0.1, int(n))
time1 = qe.toc()
```

```python
# Program 6: jit version

qe.tic() # PI: what's this? a possible link? vs %timeit
qm_numba(0.1, int(n))
time2 = qe.toc()
```

```python
# Program 7: jit for the 2nd time

qe.tic() # PI: what's this? a possible link? vs %timeit
qm_numba(0.1, int(n))
time3 = qe.toc()
```

```python
# Program 8: calculate speed gain

time1 / time3
```

# 2.2 How and when it works

1. Numba attempts to generate fast machine code using the infrastructure provided by the LLVM project. 
   - It does this by inferring type information on the fly.
     - See our earlier lecture on scientific computing for a discussion of types, 2.1 need for speed.
   - The basic idea is that:
     - Python is very flexible(**PI:,**) and hence we could call the function `qm` with many types.
       - e.g., `x0` could be a NumPy array or a list, `n` could be an integer or a float, etc.
     - This makes it hard to **pre-compile** the function.
     - However, when we do actually call the function, by executing `qm(0.5, 10)`(**PI1: add ` `**), say, the types of `x0` and `n` become clear.
     - Moreover, the types of other variables in `qm` can be inferred once the input is known.
     - So the strategy of Numba and other JIT compilers is to wait until this moment, and then compile the function.
   - This is why it is called "just-in-time" compilation.
2. Note that
   - If we make the call `qm(0.5, 10)` (**PI1: add ` `**) and then follow it with `qm(0.9, 20)`, compilation only takes place on the first call.
   - The compiled code is then cached and recycled as required.


# 3 decorators and "nopython" mode

1. In the code above, we created a JIT(**PI:-**)compiled version of `qm` via the call `qm_numba = jit(qm)`.
   - In practice(**PI:,**) this would typically be done using an alternative **decorator syntax**.

## 3.1 decorator notation

1. To target a function for JIT compilation(**PI:,**) we can put `@jit` before the function definition.
   - Here's what this looks like for `qm` (**PI: ?**), see Program 1.
     - This is equivalent to `qm = jit(qm)`.
     - Application of the jitted version, see Program 2.

```python
# Program 1

@jit
def qm(x0, n):
    x = np.empty(n+1)
    x[0] = x0
    for t in range(n):
        x[t+1] = α * x[t] * (1 - x[t])
    return x
```

```python
# Program 2

qm(0.1, 10)
```

## 3.2 type inference and "nopython" mode

1. Clearly type inference is a key part of JIT compilation.
   - As we can imagine, inferring types is easier for simple Python objects (e.g., simple scalar data types, such as floats and integers).
   - Numba also plays well with **NumPy arrays**.
2. In an ideal setting, Numba **can infer all necessary type information**.
   - This allows it to generate native machine code, without having to call the Python runtime environment.
   - In such a setting, Numba will be on par with machine code from low-level languages.
3. When Numba **cannot infer all type information**, some Python objects are given generic `object` status and execution falls back to the Python runtime.
   - When this happens, Numba provides only minor speed gains or none at all.
   - We generally prefer to force an error when this occurs, so we know effective compilation is failing.
     - This is done by using either `@jit(nopython=True)` or, equivalently, `@njit` instead of `@jit`.
     - e.g., see Program 3.

```python
# Program 3

from numba import njit

@jit
def qm(x0, n):
    x = np.empty(n+1)
    x[0] = x0
    for t in range(n):
        x[t+1] = 4 * x[t] * (1 - x[t])
    return x
```

# 4 compiling classes

1. As mentioned above, at present Numba can only compile a subset of Python.
   - However, that subset is ever(**PI:-**)expanding.
     - e.g. Numba is now quite effective at **compiling classes**.
   - If a class is successfully compiled, then its methods acts (**PI4: act**) as JIT-compiled functions.
     - To give one example, let's consider the class for anlayzing the Solow growth model we created in lecture 1.6, see Program 1-2.
       - To compile this class(**PI:,**) we use the `@jitclass` decorator (**PI1: add ` `**), see Program 1.
         - Notice that we also imported something called `float64`.
           - This is a **data type** representing **standard floating(**PI:-**)point numbers**.
           - We are importing it here because Numba needs a bit of extra help with types when it trys to deal with classes.
       - First, we specified the types of the instance data for the class in `solow_data` (**PI1: add ` `**), see Program 2-1.
       - After that, targeting the class for JIT compilation only requires adding `@jitclass(solow_data)` before the class definition, see Program 2-2.
     - When we call the methods in the class, the methods are compiled just like functions.

```python
# Program 1
from numba import jitclass, float64
```

```python
# Program 2-1

solow_data = [
    ('n', float64),
    ('s', float64),
    ('δ', float64),
    ('α', float64),
    ('z', float64),
    ('k', float64)
]

# Program 2-2

@jitclass(solow_data)
class Solow:
    r"""
    Implements the Solow growth model with the update rule (1)
    
    """
    def __init__(self, 
                 n=0.05, 
                 s=0.25, 
                 δ=0.1, 
                 α=0.3, 
                 z=2.0, 
                 k=1.0):
        self.n, self.s, self.δ, self.α, self.z = n, s, δ, α, z
        self.k = k
        
    def h(self):
        "Evaluate the h function"
        
        # Unpack parameters (aim: getting rid of `self` to simplify notation, but can we just use `self.xx`?)
        n, s, δ, α, z = self.n, self.s, self.δ, self.α, self.z
        
        # Apply the update rule
        return (s * z * self.k**α + (1- δ) * self.k) / (1+n)
    
    def update(self):
        "Update the current state (i.e., the capital stock)."
        self.k = self.h()
        
    def steady_state(self):
        "Compute the steady state value of capital."
        
        # Unpack parameters (aim: getting rid of `self` to simplify notation, but can we just use `self.xx`?)
        n, s, δ, α, z = self.n, self.s, self.δ, self.α, self.z
        
        # Compute and return steady state
        return ((s * z) / (n + δ)) ** (1 / (1 - α))
    
    def generate_sequence(self, t):
        "Generate and return a time series of length t"
        path = []
        for i in range(t):
            path.append(self.k)
            self.update()
        return path
```

```python
# Program 3

s1 = Solow()
s2 = Solow(k=8.0)

T = 60
fig, ax = plt.subplots()

# Plot the common steady state value of capital
ax.plot([s1.steady_state()] * T, 'k-', label='steady state')

# Plot time series for each economy
for s in s1, s2:
    lb = f'capital series from initial state {s.k}'
    ax.plot(s.generate_sequence(T), 'o-', lw=2, alpha=0.6, label=lb)

ax.legend()
plt.show()
```

<!-- #region -->
# 5 alternatives to numba

1. There are additional options for accelerating Python loops, and we will quickly review them.
   - However, we do so only for interest and completeness, so we can safely skip this section.

## 5.1 cypthon

1. Like Numba, Cypthon provides an approach to generating fast compiled code that can be used from Python.
2. As was the case with Numba, a key problem is the fact that Python is dynamically typed.
   - As we recall, Numba solves this problem by **inferring type**.
   - Cython's approach is different.
     - Programmers add type definitions **directly to their "Python" code** (**???**).
       - As such, the Cython language can be thought of as Python with type definitions.
     - In addition to a language specification, Cython is also a **language translator**, transforming **Cython code** into **optimized C and C++ code**.
     - Cython also takes care of **building language extensions**.
       - The wrapper code that interfaces between the resulting compiled code and Python.
   - While Cython has certain advantages, we generally find it both **slower and more cumbersome** than Numba.


## 5.2 interfacing with fortran via F2Py

1. If we are comfortable writing Fortran, then we will find it very easy to create extension modules from Fortran code using F2Py.
   - F2Py is a Fortran-to-Python interface generator that is particularly simple to use.
   - Robert Johansson provides a nice introduction to F2Py, among other things.
   - Recently, a Jupyter cell magic for Fortran has been developed.
<!-- #endregion -->

# 6 summary and comments

Let's review the above and add some cautionary notes.

## 6.1 limitations

1. As we've seen, Numba needs to infer type information on all variables to generate fast machine-level instructions.
   - For simple routines, Numba infers types very well.
   - For larger ones, or for routines using external libraries, it can easily fail.
2. Hence, it's prudent when using Numba to focus on speeding up small, time-critical snippets of code.
   - This will give us much better performance than blanketing our Python programs with `@jit` statements.

## 6.2 a Gotcha: global variables
1. Here's another thing to be careful about when using Numba.
   - Consider Program 1-2.
   - Notice that changing the global had no effect on the value returned by the function.
     - When Numba compiles machine code for functions, it treats global variables as constants to ensure type stability (**???**).


```python
# Program 1

a = 1

@jit
def add_a(x):
    return a + x

print(add_a(10))
```

```python
# Program 1

a = 2
print(add_a(10))
```

# 7 exercises

## Exercise 1


```python
def π(length_ts=10000, r=1):
    i = 0
    s_c = 0
    while i <= length_ts: # We can replace it with 
        u = [np.random.uniform(0,1) for i in range(2)]
        x, y = u
        a = x**2 + y**2
        if a <= 1:
            s_c += 1
        else:
            s_c += 0
        i += 1
    s = s_c / length_ts
    return (s * 4) / (r**2)
```

```python
from numba import jit

π_numba = jit(π)
```

```python
length_ts = 1000_000

qe.tic()
π(length_ts)
time1 = qe.toc()
```

```python
qe.tic()
π_numba(length_ts)
time2 = qe.toc()
```

```python
time1 / time2
```

## Exercise 2

```python
np.random.binomial(1, 0.8)
```

```python
def vol(p1=0.9, p2=0.8, n=1_000_000):
    x = np.empty(n, dtype=np.int_)
    x[0] = 1
    for i in range(0, n-1):
        if x[i] == 1: # PI: change the assignment
            x[i+1] = np.random.binomial(1, p2)
        if x[i] == 0:
            x[i+1] = np.random.binomial(1, 1-p1)
    return x
```

```python
vol_numba = jit(vol)
```

```python
qe.tic()
vol()
time1 = qe.toc()
```

```python
qe.tic()
vol_numba()
time2 = qe.toc()
```

```python
time1 / time2 # # PI: add a division of times
```

```python
def count(x, n=1_000_000):
    c = 0
    for i in range(len(x)):
        if x[i] == 0:
            c += 1
    return c / n
```

```python
x1 = vol()
x2 = vol_numba()
count(x1)
```

```python
count(x2)
```

```python

```
